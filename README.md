# Question-Answering Chatbot with Fine-Tuning and Sentiment Analysis Using Hugging Face Transformers

Welcome to this repository! This project explores the **Question Answering (Qu-An)** task in **Natural Language Processing (NLP)** using pre-trained models from **Hugging Face**. This README will guide you through the concepts, implementation, and use cases of question answering models.

---

## ğŸš€ Project Overview

Question answering is a fascinating and practical application of NLP. It involves answering questions posed by a user based on a given context or input body of text. Some key applications include:

- **Self-service systems**: Answering customer queries based on product catalogs.
- **Knowledge retrieval**: Searching encyclopedias or large text corpora for answers to user queries.

---

## ğŸ” How Question Answering Works

### Input Components:
1. **Corpus/Context**: The body of text that serves as the knowledge base.
2. **Question**: The query posed by the user.

### Key Steps:
1. **Tokenization & Vectorization**: 
   - Both the input corpus and the user's question are tokenized and converted into numerical representations (vectors).
2. **Model Inference**:
   - The model compares the tokenized question with the context to find the most relevant segments.
   - Multiple candidate answers are scored.
3. **Answer Extraction**:
   - The model extracts the best-matching text snippet from the context.

### Tools Used:
- **Hugging Face Transformers**:
  - Provides pre-trained models and pipelines for streamlined question-answering tasks.

---

## ğŸ› ï¸ Features

- **Easy-to-use Pre-trained Models**:
  - Quickly deploy question answering models with minimal setup.
- **Custom Context Input**:
  - Define a specific body of text to act as the knowledge base for answering questions.
- **Interactive Implementation**:
  - Python scripts and Jupyter notebooks for hands-on experimentation.

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ question_answering_demo.ipynb    # Interactive demo using Hugging Face pipelines
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_question_answering.py        # Script for standalone question answering tasks
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_context.txt               # Sample context files for testing
â”œâ”€â”€ README.md                            # This file
```

---

## ğŸ§‘â€ğŸ’» How to Use

### 1. Clone the Repository
```bash
git clone https://github.com/thuc-nguyen-oamk/qu-an-chatbot.git
cd qu-an-chatbot
```

### 2. Set Up the Environment
- Install dependencies:
```bash
pip install -r requirements.txt
```
- Requirements include:
  - `transformers`
  - `torch`
  - `numpy`
  - `jupyter`

### 3. Run the Jupyter Notebook
- Launch the interactive notebook:
```bash
jupyter notebook notebooks/question_answering_demo.ipynb
```

### 4. Execute the Script
- Use the script for standalone execution:
```bash
python scripts/run_question_answering.py --context "sample_context.txt" --question "What is NLP?"
```

---

## ğŸ“ˆ Results and Examples

- **Input Context**: 
  > "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language."
- **Input Question**:
  > "What is NLP?"
- **Output Answer**:
  > "a field of artificial intelligence that focuses on the interaction between computers and humans through natural language."

---

## ğŸ’¡ Key Concepts and Insights

- Hugging Face's **pipeline** API significantly simplifies the implementation process.
- Pre-trained models like **BERT**, **RoBERTa**, and **DistilBERT** are powerful for question answering tasks.
- Custom contexts can be used for domain-specific queries.

---

## ğŸ¤ Contributions

Contributions are welcome! Feel free to open issues or pull requests to improve this project.

---

## ğŸ“„ License

This project is licensed under the MIT License.

---

## ğŸ”— References

- [Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers/)
- [Pre-trained Models for NLP](https://huggingface.co/models)

---

## ğŸŒŸ Acknowledgments

Special thanks to Hugging Face for providing such an excellent library for NLP tasks. ğŸ‰
